{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROJET GENERATIVE AI\n",
    "\n",
    "## Carlene TUNGAMWESE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problématique : \n",
    "Bien que le langage SQL soit devenu une compétence essentielle pour les métiers de l'analyse de données, notamment pour les futurs Data Analysts, il est souvent négligé. De nombreux étudiants atteignent le niveau de Master 2 sans avoir acquis les bases du SQL, ce qui les désavantage face aux exigences du marché du travail. Cette lacune constitue un frein à leur insertion professionnelle, surtout dans des domaines tels que la finance, la banque, et l'assurance, où l’exploitation de bases de données est primordiale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approche : \n",
    "Pour combler ce manque, l’idée est de développer un chatbot pédagogique interactif destiné aux étudiants, mais également accessible à tous ceux souhaitant apprendre SQL. Ce chatbot permettra d’apprendre et de pratiquer le langage SQL de manière autonome et ludique, grâce à des exercices progressifs et des explications adaptées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "\n",
    "# Charger les variables d'environnement à partir du fichier .env\n",
    "load_dotenv()\n",
    "\n",
    "# Obtenir la clé API\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Traitement des fichiers Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\n",
    "import os\n",
    "from yt_dlp import YoutubeDL\n",
    "\n",
    "# Définir le répertoire de sauvegarde\n",
    "save_dir = \"docs/youtube/\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# URLs de vidéos YouTube individuelles\n",
    "urls = [\n",
    "    \"https://www.youtube.com/watch?v=LRjnjipMe54\",\n",
    "    \"https://www.youtube.com/watch?v=bpRirgAiyhw\",\n",
    "    \"https://www.youtube.com/watch?v=4Ro69oqZ20s\",\n",
    "    \"https://www.youtube.com/watch?v=g9yC8pcdRFc\",\n",
    "    \"https://www.youtube.com/watch?v=kawRFZMQ-60\",\n",
    "    \"https://www.youtube.com/watch?v=mc4zOX1j7_A\",\n",
    "    \"https://www.youtube.com/watch?v=9Aj9X-j1Yys\"\n",
    "]\n",
    "\n",
    "# Configuration de yt_dlp\n",
    "ydl_opts = {\n",
    "    'format': 'bestaudio/best',\n",
    "    'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'mp3',\n",
    "        'preferredquality': '192',\n",
    "    }],\n",
    "    'ffmpeg_location': 'C:/ffmpeg',  # Assurez-vous que ce chemin est correct\n",
    "    'outtmpl': os.path.join(save_dir, '%(title)s.%(ext)s'),\n",
    "    'noplaylist': True,\n",
    "    'ignoreerrors': True,\n",
    "    'download_archive': os.path.join(save_dir, 'downloaded_videos.txt')\n",
    "}\n",
    "\n",
    "# Télécharger et extraire l'audio\n",
    "with YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download(urls)\n",
    "\n",
    "# Vérifier l'existence de ffmpeg et imprimer la confirmation\n",
    "ffmpeg_path = os.path.join(ydl_opts['ffmpeg_location'], 'ffmpeg.exe')\n",
    "if os.path.exists(ffmpeg_path):\n",
    "    print(\"FFmpeg est correctement installé à :\", ffmpeg_path)\n",
    "else:\n",
    "    print(\"Le chemin de FFmpeg n'est pas correct :\", ffmpeg_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to c:\\users\\carlène tungamwese\\appdata\\local\\temp\\pip-req-build-onik3vy3\n",
      "  Resolved https://github.com/openai/whisper.git to commit 25639fc17ddc013d56c594bfbf7644f2185fad84\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numba in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from openai-whisper==20240930) (0.60.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from openai-whisper==20240930) (1.26.4)\n",
      "Requirement already satisfied: torch in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from openai-whisper==20240930) (2.4.1+cu118)\n",
      "Requirement already satisfied: tqdm in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from openai-whisper==20240930) (4.66.5)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from openai-whisper==20240930) (10.5.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from openai-whisper==20240930) (0.8.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from tiktoken->openai-whisper==20240930) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from torch->openai-whisper==20240930) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from torch->openai-whisper==20240930) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from torch->openai-whisper==20240930) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from torch->openai-whisper==20240930) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from torch->openai-whisper==20240930) (2024.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from tqdm->openai-whisper==20240930) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from jinja2->torch->openai-whisper==20240930) (3.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from sympy->torch->openai-whisper==20240930) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git 'C:\\Users\\carlène Tungamwese\\AppData\\Local\\Temp\\pip-req-build-onik3vy3'\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whisper import load_model\n",
    "\n",
    "# Charger le modèle Whisper (choisir la taille selon vos besoins: 'tiny', 'base', 'small', 'medium', 'large')\n",
    "model = load_model(\"tiny\")\n",
    "\n",
    "# Chemin vers le dossier contenant les fichiers\n",
    "docs_folder = \"docs/youtube\"\n",
    "\n",
    "# Lister tous les fichiers dans le dossier\n",
    "file_list = os.listdir(docs_folder)\n",
    "\n",
    "# Parcourir chaque fichier et appliquer Whisper\n",
    "for file_name in file_list:\n",
    "    file_path = os.path.join(docs_folder, file_name)\n",
    "    \n",
    "    # Transcription avec Whisper\n",
    "    print(f\"Transcription de {file_name} en cours...\")\n",
    "    result = model.transcribe(file_path)\n",
    "    \n",
    "    # Afficher ou sauvegarder la transcription\n",
    "    transcription = result['text']\n",
    "    print(f\"Transcription de {file_name} :\\n{transcription}\\n\")\n",
    "    \n",
    "    # Vous pouvez également sauvegarder la transcription dans un fichier texte\n",
    "    with open(f\"{file_name}_transcription.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Etape 1 : Charger les fichiers PDF, .txt et .ipynb\n",
    "\n",
    "Dans cette étape, nous allons parcourir notre répertoire et charger les fichiers PDF et .ipynb. Nous utiliserons PyPDFLoader pour les PDF et TextLoader pour les fichiers .ipynb et .txt. Ensuite, nous découperons les documents en petits morceaux pour faciliter l'indexation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du fichier PDF : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\0072-cours-langage-sql.pdf\n",
      "108 document(s) chargé(s) depuis 0072-cours-langage-sql.pdf\n",
      "Chargement du fichier PDF : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\0172-formation-base-donnees.pdf\n",
      "50 document(s) chargé(s) depuis 0172-formation-base-donnees.pdf\n",
      "Chargement du fichier PDF : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\0230-formation-base-donnees-langage-sql.pdf\n",
      "114 document(s) chargé(s) depuis 0230-formation-base-donnees-langage-sql.pdf\n",
      "Chargement du fichier PDF : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\0320-programmation-sql-sgbd.pdf\n",
      "18 document(s) chargé(s) depuis 0320-programmation-sql-sgbd.pdf\n",
      "Chargement du fichier PDF : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\0515-pdf-mysql-workbench.pdf\n",
      "15 document(s) chargé(s) depuis 0515-pdf-mysql-workbench.pdf\n",
      "Chargement du fichier PDF : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\ACFrOgAd8_Amg7MaX0OiU1_e6XczUV95OWEdjhKScvTiEjnfM6-afuzbxgKx7PAVXKnRkvl8APEKYPhEiBOTsR1CwFOauApd9VGHFSKeBi04bJBX-bexQVBYbhH__P118_Mhq-206MzkbnfCfXsR.pdf\n",
      "6 document(s) chargé(s) depuis ACFrOgAd8_Amg7MaX0OiU1_e6XczUV95OWEdjhKScvTiEjnfM6-afuzbxgKx7PAVXKnRkvl8APEKYPhEiBOTsR1CwFOauApd9VGHFSKeBi04bJBX-bexQVBYbhH__P118_Mhq-206MzkbnfCfXsR.pdf\n",
      "Chargement du fichier PDF : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\ACFrOgBbzY9aoniTbK6D1PSvKOX3zPMTKkRqtcMlD3N7LsgDyKqFUVJBRajnZ55yx79dBB-GkrG9kx6dH48YQOZxXRQXhZ18jo1Pe6CcBcouExFDIEg0kJUCrjTOnOWjTrY16jOZB4lif2wHERQ5.pdf\n",
      "6 document(s) chargé(s) depuis ACFrOgBbzY9aoniTbK6D1PSvKOX3zPMTKkRqtcMlD3N7LsgDyKqFUVJBRajnZ55yx79dBB-GkrG9kx6dH48YQOZxXRQXhZ18jo1Pe6CcBcouExFDIEg0kJUCrjTOnOWjTrY16jOZB4lif2wHERQ5.pdf\n",
      "Chargement du fichier Jupyter Notebook : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\as-with.ipynb\n",
      "1 document(s) chargé(s) depuis as-with.ipynb\n",
      "Chargement du fichier PDF : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\cours-sql-sh-.pdf\n",
      "89 document(s) chargé(s) depuis cours-sql-sh-.pdf\n",
      "Chargement du fichier Jupyter Notebook : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\explore-your-data.ipynb\n",
      "1 document(s) chargé(s) depuis explore-your-data.ipynb\n",
      "Chargement du fichier Jupyter Notebook : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\getting-started-with-sql-and-bigquery.ipynb\n",
      "1 document(s) chargé(s) depuis getting-started-with-sql-and-bigquery.ipynb\n",
      "Chargement du fichier Jupyter Notebook : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\group-by-having-count.ipynb\n",
      "1 document(s) chargé(s) depuis group-by-having-count.ipynb\n",
      "Chargement du fichier PDF : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\introductionSQL.pdf\n",
      "75 document(s) chargé(s) depuis introductionSQL.pdf\n",
      "Chargement du fichier Jupyter Notebook : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\joining-data.ipynb\n",
      "1 document(s) chargé(s) depuis joining-data.ipynb\n",
      "Chargement du fichier PDF : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\learning-sql.pdf\n",
      "221 document(s) chargé(s) depuis learning-sql.pdf\n",
      "Chargement du fichier Jupyter Notebook : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\order-by.ipynb\n",
      "1 document(s) chargé(s) depuis order-by.ipynb\n",
      "Chargement du fichier PDF : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\Présentation Cours SQL.pdf\n",
      "34 document(s) chargé(s) depuis Présentation Cours SQL.pdf\n",
      "Chargement du fichier Jupyter Notebook : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\select-from-where.ipynb\n",
      "1 document(s) chargé(s) depuis select-from-where.ipynb\n",
      "Chargement du fichier PDF : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\sql.pdf\n",
      "165 document(s) chargé(s) depuis sql.pdf\n",
      "Chargement du fichier texte : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\SQL.txt\n",
      "1 document(s) chargé(s) depuis SQL.txt\n",
      "Chargement du fichier texte : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\SQL1.txt\n",
      "1 document(s) chargé(s) depuis SQL1.txt\n",
      "Chargement du fichier texte : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\SQL2.txt\n",
      "1 document(s) chargé(s) depuis SQL2.txt\n",
      "Chargement du fichier texte : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\SQL3.txt\n",
      "1 document(s) chargé(s) depuis SQL3.txt\n",
      "Chargement du fichier texte : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\SQL4.txt\n",
      "1 document(s) chargé(s) depuis SQL4.txt\n",
      "Chargement du fichier texte : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\SQL5.txt\n",
      "1 document(s) chargé(s) depuis SQL5.txt\n",
      "Chargement du fichier PDF : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\Week+1.pdf\n",
      "10 document(s) chargé(s) depuis Week+1.pdf\n",
      "Chargement du fichier PDF : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\Week+2.pdf\n",
      "7 document(s) chargé(s) depuis Week+2.pdf\n",
      "Chargement du fichier PDF : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\Week+3.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 24 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 document(s) chargé(s) depuis Week+3.pdf\n",
      "Chargement du fichier PDF : C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\Week+4.pdf\n",
      "14 document(s) chargé(s) depuis Week+4.pdf\n",
      "Total de documents chargés et découpés : 2559\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def load_files_from_directory(directory):\n",
    "    docs = []\n",
    "    \n",
    "    # Parcourir tous les fichiers dans le répertoire\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        # Charger les fichiers PDF\n",
    "        if filename.endswith('.pdf'):\n",
    "            print(f\"Chargement du fichier PDF : {file_path}\")\n",
    "            loader = PyPDFLoader(file_path)\n",
    "            documents = loader.load()\n",
    "\n",
    "        # Charger les fichiers Jupyter Notebook (.ipynb)\n",
    "        elif filename.endswith('.ipynb'):\n",
    "            print(f\"Chargement du fichier Jupyter Notebook : {file_path}\")\n",
    "            loader = TextLoader(file_path, encoding='utf-8')\n",
    "            documents = loader.load()\n",
    "\n",
    "        # Charger les fichiers texte (.txt)\n",
    "        elif filename.endswith('.txt'):\n",
    "            print(f\"Chargement du fichier texte : {file_path}\")\n",
    "            loader = TextLoader(file_path, encoding='utf-8')\n",
    "            documents = loader.load()\n",
    "\n",
    "        else:\n",
    "            print(f\"Type de fichier non supporté : {filename}\")\n",
    "            continue\n",
    "\n",
    "        if not documents:\n",
    "            print(f\"Aucun document chargé depuis {filename}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"{len(documents)} document(s) chargé(s) depuis {filename}\")\n",
    "        \n",
    "        # Diviser le document en morceaux plus petits\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "        split_docs = text_splitter.split_documents(documents)\n",
    "        docs += split_docs\n",
    "\n",
    "    return docs\n",
    "\n",
    "# Utilisation de la fonction avec votre répertoire\n",
    "directory = r\"C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\"\n",
    "documents = load_files_from_directory(directory)\n",
    "\n",
    "# Affichage du nombre de documents chargés et découpés\n",
    "print(f\"Total de documents chargés et découpés : {len(documents)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etape 2 : Étape 2 : Indexer les documents avec OpenAI Embeddings\n",
    "\n",
    "Maintenant que les documents sont chargés et découpés, nous allons les indexer en utilisant des embeddings générés par OpenAI. Cela permettra de rechercher des documents par similarité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docarray in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (0.40.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from docarray) (1.26.4)\n",
      "Requirement already satisfied: orjson>=3.8.2 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from docarray) (3.10.7)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from docarray) (2.9.2)\n",
      "Requirement already satisfied: rich>=13.1.0 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from docarray) (13.9.2)\n",
      "Requirement already satisfied: types-requests>=2.28.11.6 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from docarray) (2.32.0.20240914)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from docarray) (0.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from pydantic>=1.10.8->docarray) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from pydantic>=1.10.8->docarray) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from pydantic>=1.10.8->docarray) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from rich>=13.1.0->docarray) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from rich>=13.1.0->docarray) (2.18.0)\n",
      "Requirement already satisfied: urllib3>=2 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from types-requests>=2.28.11.6->docarray) (2.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from typing-inspect>=0.8.0->docarray) (1.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\carlène tungamwese\\onedrive\\bureau\\nouveau dossier\\formation\\generative ai\\env_generative_ai\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install docarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexation terminée.\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "def index_documents(docs):\n",
    "    # Créer des embeddings pour les documents\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    \n",
    "    # Indexer les documents dans une base de données vectorielle\n",
    "    db = DocArrayInMemorySearch.from_documents(docs, embeddings)\n",
    "    \n",
    "    # Créer un récupérateur pour interroger la base de données vectorielle\n",
    "    retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "    \n",
    "    return retriever\n",
    "\n",
    "# Indexer les documents\n",
    "retriever = index_documents(documents)\n",
    "\n",
    "print(\"Indexation terminée.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etape 3 : Créer la chaîne de questions-réponses conversationnelle\n",
    "\n",
    "Nous allons maintenant créer la chaîne de questions-réponses (QA) en utilisant ConversationalRetrievalChain, ce qui permettra d'interagir avec les documents de manière conversationnelle, en utilisant GPT-3.5 pour répondre aux questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chaîne de questions-réponses créée.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "def create_qa_chain(retriever, model_name='gpt-3.5-turbo'):\n",
    "    # Créer une mémoire pour stocker l'historique de la conversation\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True, output_key=\"answer\")\n",
    "    \n",
    "    # Créer la chaîne de questions-réponses conversationnelle\n",
    "    qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=ChatOpenAI(model_name=model_name, temperature=0), \n",
    "        retriever=retriever, \n",
    "        memory=memory,\n",
    "        return_source_documents=True,\n",
    "        output_key=\"answer\"  # Indique que la clé \"answer\" est la sortie principale\n",
    "    )\n",
    "    \n",
    "    return qa_chain\n",
    "\n",
    "# Créer la chaîne QA\n",
    "qa_chain = create_qa_chain(retriever)\n",
    "\n",
    "print(\"Chaîne de questions-réponses créée.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etape 4 : Poser des questions à la chaîne QA\n",
    "\n",
    "Enfin, nous allons interagir avec la chaîne QA en posant des questions. La chaîne générera des réponses basées sur les documents indexés et fournira également les documents sources utilisés pour répondre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse :  Je suis désolé, mais il semble y avoir une confusion. SQL (Structured Query Language) n'est pas un logiciel à installer, c'est un langage de programmation utilisé pour interagir avec les bases de données relationnelles telles que MySQL, PostgreSQL, SQL Server, etc. \n",
      "\n",
      "Pour installer un système de gestion de base de données relationnelle comme MySQL, vous pouvez suivre les instructions spécifiques à chaque système sur leur site officiel. Par exemple, pour MySQL, vous pouvez télécharger MySQL Community Server sur le site officiel de MySQL.\n",
      "\n",
      "Un exemple de requête SQL simple serait:\n",
      "\n",
      "```sql\n",
      "SELECT * FROM nom_de_la_table;\n",
      "```\n",
      "\n",
      "Cette requête sélectionne toutes les colonnes de la table spécifiée. Vous pouvez remplacer \"nom_de_la_table\" par le nom réel de la table que vous souhaitez interroger.\n",
      "\n",
      "Documents sources :\n",
      "C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\SQL1.txt\n",
      "C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\SQL3.txt\n",
      "C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\SQL4.txt\n",
      "C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\SQL1.txt\n",
      "C:\\Users\\carlène Tungamwese\\OneDrive\\Bureau\\Nouveau dossier\\FORMATION\\GENERATIVE AI\\docs_SQL\\cours-sql-sh-.pdf\n"
     ]
    }
   ],
   "source": [
    "def ask_question(qa_chain, question):\n",
    "    # Poser une question à la chaîne QA\n",
    "    response = qa_chain({\"question\": question})\n",
    "    \n",
    "    # Afficher la réponse\n",
    "    print(\"Réponse : \", response['answer'])\n",
    "    \n",
    "    # Afficher les documents sources\n",
    "    print(\"\\nDocuments sources :\")\n",
    "    for source in response['source_documents']:\n",
    "        print(source.metadata['source'])\n",
    "\n",
    "# Exemple d'interaction : poser une question\n",
    "question = \"comment installer SQL et donnez moi un exemple d'une requete\"\n",
    "ask_question(qa_chain, question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_generative_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
